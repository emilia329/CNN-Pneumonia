{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Images\n",
    "\n",
    "In this project, we are working with images of chest X-rays which we are classifying into two categories: pneumonia or normal. First, let's look at the difference between these.\n",
    "\n",
    "#### Normal:\n",
    "<table style=\"border-collapse: collapse;\">\n",
    "    <tr>\n",
    "        <td style=\"border: none;\"><img src=\"Images/normal1.jpeg\" alt=\"normal1\" width=\"450px\"/></td>\n",
    "        <td style=\"border: none;\"><img src=\"Images/normal2.jpeg\" alt=\"normal2\" width=\"400px\"/></td>\n",
    "        <td style=\"border: none;\"><img src=\"Images/normal3.jpeg\" alt=\"normal3\" width=\"400px\"/></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "#### Pneumonia:\n",
    "<table style=\"border-collapse: collapse;\">\n",
    "    <tr>\n",
    "        <td style=\"border: none;\"><img src=\"Images/pneumonia1.jpeg\" alt=\"pneumonia1\" width=\"450px\"/></td>\n",
    "        <td style=\"border: none;\"><img src=\"Images/pneumonia2.jpeg\" alt=\"pneumonia2\" width=\"400px\"/></td>\n",
    "        <td style=\"border: none;\"><img src=\"Images/pneumonia3.jpeg\" alt=\"pneumonia3\" width=\"400px\"/></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "From <a href=\"https://www.radiologyinfo.org/en/info.cfm?pg=pneumonia\">Radiology.org</a>: <br> _Pneumonia is an infection that causes inflammation in one or both of the lungs. It can be caused by a virus, bacteria, fungi or other germs. The infection is usually acquired when a person breathes in air carrying germs._\n",
    "\n",
    "When radiologists look at these images, they look for white spots called infiltrates that identify an infection, as well as abscesses or fluids that could be caused by pneumonia. We find it a bit difficult to tell the difference between these due to not being trained radiologists, but we can definitely say some x-rays (such as the leftmost pneumonia picture above) look more \"cloudy\" than others.\n",
    "\n",
    "Further reviewing our data, we can see that:\n",
    "* Every image is grayscale, only containing color data in the gray channel (as opposed to RGB alpha channels).\n",
    "* Each image has a different pixel dimension, many with non-square aspect ratios. \n",
    "* Most images have tick marks on the left and right edges.\n",
    "* Many images contain other text near the edges.\n",
    "* Some images show the patient rotated at an angle.\n",
    "\n",
    "<img src=\"Images/tp_512_prob.png\" alt=\"image_problems\" width=\"450px\"/>\n",
    "\n",
    "To remedy any issues caused by this, we will change parameters of ImageDataGenerator while creating our models.\n",
    "\n",
    "## Class Distribution\n",
    "\n",
    "Before we start modeling, we want to check for class imbalance. Our data is split into 3 directories, each holding the images needed for our test, train, and validation sets. We'll add up the number of files in these directories to get the count of data points in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_count = len(os.listdir('chest_xray/test/NORMAL')) + len(os.listdir('chest_xray/train/NORMAL')) + len(os.listdir('chest_xray/val/NORMAL'))\n",
    "p_count = len(os.listdir('chest_xray/test/PNEUMONIA')) + len(os.listdir('chest_xray/train/PNEUMONIA')) + len(os.listdir('chest_xray/val/PNEUMONIA'))\n",
    "\n",
    "objects = (f'Normal: {n_count}', f'Pneumonia: {p_count}')\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.bar(y_pos, [n_count,p_count], align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Data Points')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we have a 27:73 split. This isn't a huge imbalance, but definitely something to keep in mind when evaluating our models, as our null accuracy is 73%. This is the accuracy we could achieve by always predicting the most frequent class.\n",
    "\n",
    "# Modeling\n",
    "\n",
    "## Gather Image Data\n",
    "\n",
    "First, we get the image data from our folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory('chest_xray/train/', target_size=(64, 64), batch_size = 5218)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory('chest_xray/test/', target_size=(64, 64), batch_size = 624)\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory('chest_xray/val/', target_size=(64, 64), batch_size = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll make a list of matrices per image from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images shape: (5216, 64, 64, 3)\n",
      "train_labels shape: (5216, 2)\n",
      "test_images shape: (624, 64, 64, 3)\n",
      "test_labels shape: (624, 2)\n",
      "val_images shape: (16, 64, 64, 3)\n",
      "val_labels shape: (16, 2)\n"
     ]
    }
   ],
   "source": [
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our label arrays have 2 columns, one for True and one for False. We only need one of these as having two is redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (5216,1))\n",
    "test_y = np.reshape(test_labels[:,0], (624,1))\n",
    "val_y = np.reshape(val_labels[:,0], (16,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = models.Sequential()\n",
    "model_1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_1.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_1.add(layers.Flatten())\n",
    "model_1.add(layers.Dense(64, activation='relu'))\n",
    "model_1.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1.compile(loss='binary_crossentropy', optimizer=\"sgd\", metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 16 samples\n",
      "Epoch 1/30\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.5675 - acc: 0.7429 - val_loss: 0.9412 - val_acc: 0.5000\n",
      "Epoch 2/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.5255 - acc: 0.7454 - val_loss: 0.7597 - val_acc: 0.5000\n",
      "Epoch 3/30\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.4708 - acc: 0.7795 - val_loss: 1.0091 - val_acc: 0.5625\n",
      "Epoch 4/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.3971 - acc: 0.8234 - val_loss: 0.6720 - val_acc: 0.6250\n",
      "Epoch 5/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.3352 - acc: 0.8608 - val_loss: 0.7418 - val_acc: 0.6250\n",
      "Epoch 6/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.2493 - acc: 0.8974 - val_loss: 0.8306 - val_acc: 0.6250\n",
      "Epoch 7/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.2152 - acc: 0.9132 - val_loss: 0.7312 - val_acc: 0.5625\n",
      "Epoch 8/30\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.1904 - acc: 0.9210 - val_loss: 0.5216 - val_acc: 0.8125\n",
      "Epoch 9/30\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.1649 - acc: 0.9316 - val_loss: 0.4045 - val_acc: 0.8125\n",
      "Epoch 10/30\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.1565 - acc: 0.9360 - val_loss: 0.6282 - val_acc: 0.6875\n",
      "Epoch 11/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1475 - acc: 0.9431 - val_loss: 0.4394 - val_acc: 0.7500\n",
      "Epoch 12/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1371 - acc: 0.9456 - val_loss: 0.3193 - val_acc: 0.8750\n",
      "Epoch 13/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1374 - acc: 0.9479 - val_loss: 0.3130 - val_acc: 0.8750\n",
      "Epoch 14/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1280 - acc: 0.9488 - val_loss: 0.5199 - val_acc: 0.7500\n",
      "Epoch 15/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1219 - acc: 0.9496 - val_loss: 0.3923 - val_acc: 0.8125\n",
      "Epoch 16/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1243 - acc: 0.9523 - val_loss: 0.3477 - val_acc: 0.8125\n",
      "Epoch 17/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1176 - acc: 0.9525 - val_loss: 0.2795 - val_acc: 0.8750\n",
      "Epoch 18/30\n",
      "5216/5216 [==============================] - 11s 2ms/step - loss: 0.1144 - acc: 0.9561 - val_loss: 0.6614 - val_acc: 0.6875\n",
      "Epoch 19/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1110 - acc: 0.9569 - val_loss: 0.6043 - val_acc: 0.7500\n",
      "Epoch 20/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1049 - acc: 0.9592 - val_loss: 0.2699 - val_acc: 0.8125\n",
      "Epoch 21/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.1042 - acc: 0.9588 - val_loss: 0.2509 - val_acc: 0.9375\n",
      "Epoch 22/30\n",
      "5216/5216 [==============================] - 11s 2ms/step - loss: 0.0996 - acc: 0.9615 - val_loss: 0.2699 - val_acc: 0.8125\n",
      "Epoch 23/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.0986 - acc: 0.9617 - val_loss: 0.6303 - val_acc: 0.6875\n",
      "Epoch 24/30\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.0962 - acc: 0.9611 - val_loss: 1.3049 - val_acc: 0.5625\n",
      "Epoch 25/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.0968 - acc: 0.9632 - val_loss: 0.2433 - val_acc: 0.9375\n",
      "Epoch 26/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.0934 - acc: 0.9632 - val_loss: 0.4798 - val_acc: 0.7500\n",
      "Epoch 27/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.0889 - acc: 0.9666 - val_loss: 0.2645 - val_acc: 0.8750\n",
      "Epoch 28/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.0861 - acc: 0.9666 - val_loss: 1.2694 - val_acc: 0.5625\n",
      "Epoch 29/30\n",
      "5216/5216 [==============================] - 10s 2ms/step - loss: 0.0856 - acc: 0.9668 - val_loss: 0.2555 - val_acc: 0.8750\n",
      "Epoch 30/30\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.0819 - acc: 0.9707 - val_loss: 0.4943 - val_acc: 0.6875\n",
      "CPU times: user 26min 19s, sys: 13min 3s, total: 39min 23s\n",
      "Wall time: 4min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_1 = model_1.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(val_images, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps_per_epoch = np.math.ceil(test_generator.samples / test_generator.batch_size)\n",
    "predictions = model_1.predict_generator(test_generator, steps=test_steps_per_epoch)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 0s 362us/step\n",
      "['loss', 'acc'] [0.9883719927225357, 0.7275640964508057]\n"
     ]
    }
   ],
   "source": [
    "results_test_1 = model_1.evaluate(test_images, test_y)\n",
    "print(model_1.metrics_names, results_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.62      1.00      0.77       390\n",
      "   PNEUMONIA       0.00      0.00      0.00       234\n",
      "\n",
      "    accuracy                           0.62       624\n",
      "   macro avg       0.31      0.50      0.38       624\n",
      "weighted avg       0.39      0.62      0.48       624\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GabbaFlabba/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "report = metrics.classification_report(test_y, predicted_classes, target_names=class_labels)\n",
    "print(report)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[390   0]\n",
      " [234   0]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(test_y, predicted_classes)\n",
    "print(confusion_matrix)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, test_X, test_y):\n",
    "    results = model.evaluate(test_X, test_y)\n",
    "    print('Loss:', results[0])\n",
    "    print('Accuracy:', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
